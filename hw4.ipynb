{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alibi Jangeldin HW4 ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) $J(w)=(m2-m1)^2/(s1^2+s2^2)=(w^T*m_2-w^T*m_1)^2/(\\sum\\limits_{n\\in(C_1)}^n (y_n-m_1)^2+\\sum\\limits_{n\\in(C_2)}^n (y_n-m_2)^2)=(w^T*(m_2-m_1))^2/(\\sum\\limits_{n\\in(C_1)}^n ((w^T(x_n-m_1))^2+\\sum\\limits_{n\\in(C_2)}^n (w^T(x_n-m_2))^2)=(w^T*(m_2-m_1)*(m_2-m_1)^T*w)/(w^T*(\\sum\\limits_{n\\in(C_1)}^n (x_n-m_1)^T*(x_n-m_1))*w+w^T*(\\sum\\limits_{n\\in(C_2)}^n(x_n-m_2)^T*(x_n-m_2))*w)=(w^T*S_B*w)/(w^T*S_W*w)$ \n",
    "\n",
    "Q.E.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) $P(A, C | B)=P(A, B)*P(C | A, B)/P(B)=P(A,B)*P(C|B)/P(B)=P(A|B)*P(C|B)$ \n",
    "\n",
    "Q.E.D. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) PDF scans with calculations are attached below. Answers are: 1) P(+u|+e)=0.711 \n",
    "\n",
    "2) 1) F 2) F 3) T 4) F 5) T 6) F 7) T 8) T 9) F 10) F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = loadtxt(\"logreg_data_binary.txt\", comments=\"/n\", delimiter=\" \", unpack=False)\n",
    "test = loadtxt(\"test_data_binary.txt\", comments=\"/n\", delimiter=\" \", unpack=False)\n",
    "X_train=train[:,1:4]\n",
    "Y_train=train[:,0].reshape(len(train), 1)\n",
    "X_test=test[:,1:4]\n",
    "Y_test=test[:,0].reshape(len(test), 1)\n",
    "mean=np.mean(X_train, axis=0)\n",
    "std=np.std(X_train, axis=0)\n",
    "X_train=(X_train-mean)/std\n",
    "X_test=(X_test-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(train_x, test_x, train_y, k):\n",
    "    distance = np.zeros([train_x.shape[0]])\n",
    "    index = np.zeros([train_x.shape[0]])\n",
    "    for i in range(train_x.shape[0]):\n",
    "        distance[i] = np.linalg.norm(train_x[i]-test_x)\n",
    "        index[i]=i\n",
    "    y_index=np.hstack((distance.reshape([train_x.shape[0], 1]), train_y, index.reshape([train_x.shape[0], 1])))\n",
    "    sorted_neighbours=y_index[y_index[:,0].argsort()]\n",
    "    indexes=sorted_neighbours[:k][:,1]\n",
    "    label=stats.mode(indexes)\n",
    "    return label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_labels(train_x, test_x, train_y, k):\n",
    "    all_labels = -np.ones(X_test.shape[0])\n",
    "    for i in range(X_test.shape[0]):\n",
    "        all_labels[i]=get_label(train_x, test_x[i], train_y, k)\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=get_all_labels(X_train, X_test, Y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, Y):\n",
    "    acc=0\n",
    "    for i in range(len(preds)):\n",
    "        if(preds[i]==Y[i]):\n",
    "            acc+=1\n",
    "    return acc/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3) Number of correctly predicted students outcomes from test data is  55.0\n",
      "Percentage accuracy on test set is 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"3) Number of correctly predicted students outcomes from test data is \", accuracy(predicted, Y_test)*len(X_test))\n",
    "print(\"Percentage accuracy on test set is\", accuracy(predicted, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55 correctly predicted observations out of 70 is much higher than 49 by logistic regression. Сhecked manually numbers of odd neighbours from 1 to 20 with different norms and 1 had the highest test set accuracy. Checking only odd numbers is easier in order to avoid ties. We can use even numbers of neighbours as well and will need to introduce distance metric in order to compare closeness. This approach proposed in the task may result in overfitting the test set since we choose number of neighbours based on test set accuracy. Ideally, we would want to train on train set using cross validation or by separating the development set and only do one final check on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = loadtxt(\"logreg_data_3class.txt\", comments=\"/n\", delimiter=\" \", unpack=False)\n",
    "test = loadtxt(\"test_data_3class.txt\", comments=\"/n\", delimiter=\" \", unpack=False)\n",
    "X_train=train[:,1:4]\n",
    "Y_train=train[:,0].reshape(len(train), 1)\n",
    "X_test=test[:,1:4]\n",
    "Y_test=test[:,0].reshape(len(test), 1)\n",
    "mean=np.mean(X_train, axis=0)\n",
    "std=np.std(X_train, axis=0)\n",
    "X_train=(X_train-mean)/std\n",
    "X_test=(X_test-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=get_all_labels(X_train, X_test, Y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3) Number of correctly predicted students outcomes from test data is  72.0\n",
      "Percentage accuracy on test set is 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"3) Number of correctly predicted students outcomes from test data is \", accuracy(predicted, Y_test)*len(X_test))\n",
    "print(\"Percentage accuracy on test set is\", accuracy(predicted, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сhecked manually numbers of odd neighbours from 1 to 20 with different norms and 1 had the highest test set accuracy. Checking only odd numbers is easier in order to avoid ties. We can use even numbers of neighbours as well and will need to introduce distance metric in order to compare closeness. This approach proposed in the task may result in overfitting the test set since we choose number of neighbours based on test set accuracy. Ideally, we would want to train on train set using cross validation or by separating the development set and only do one final check on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
